{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Dense, Flatten, Activation, MaxPooling2D, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Conv2D, Cropping2D \n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "\n",
    "# read the csv file\n",
    "driving_df = pd.read_csv('data\\driving_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_filenames = []\n",
    "measurements = [] \n",
    "\n",
    "for index, row in driving_df.iterrows():\n",
    "    filename = row['center'][4:]\n",
    "    images_filenames.append(filename)\n",
    "    measurement = float(row['steering'])\n",
    "    measurements.append(measurement)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8036\n"
     ]
    }
   ],
   "source": [
    "print(len(images_filenames))\n",
    "#gray = plt.imshow(images[0], cmap='gray')\n",
    "#plt.imsave('gray_sample.jpg', gray)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(images_filenames, measurements, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 processed\n"
     ]
    }
   ],
   "source": [
    "# augmentation\n",
    "\n",
    "# already done grayscale\n",
    "# normalization\n",
    "#def normalize_pixels(data):\n",
    "#    return (data.astype(float) - 128) / 128\n",
    "    \n",
    "#X_train_norm = normalize_pixels(np.asarray(X_train))\n",
    "#X_valid_norm = normalize_pixels(np.asarray(X_valid))\n",
    "#X_test_norm = normalize_pixels(np.asarray(X_test))\n",
    "\n",
    "# create the generator to perform online data augmentation\n",
    "#image_generator = ImageDataGenerator(\n",
    "#                                horizontal_flip = True)\n",
    "#                                zoom_range = 0.1)\n",
    "#                                rotation_range = 10)\n",
    "#                                width_shift_range=0.2,\n",
    "#                                height_shift_range=0.2)\n",
    "\n",
    "# flip images horizontally to solve left turn bias\n",
    "#print(X_train[0])\n",
    "def flip_images(data):\n",
    "    flipped_filenames = []\n",
    "    for i in range(0, len(data)):\n",
    "        filename = data[i]\n",
    "        current_path = 'data/IMG/' + filename\n",
    "        image = mpimg.imread(current_path)\n",
    "        \n",
    "        #batch_x_one = cv2.imread(current_path)\n",
    "                #batch_x_one = cv2.cvtColor(batch_x_one, cv2.COLOR_BGR2GRAY)\n",
    "                #batch_x_one = np.expand_dims(batch_x_one[:, :], 2)\n",
    "                #batch_x.append(batch_x_one)\n",
    "                #batch_y.append(y_data_range[i])\n",
    "        #plt.imshow(image)\n",
    "        flipped_image = np.fliplr(image)\n",
    "        plt.imshow(flipped_image)\n",
    "        # save image to 'data/IMG/'\n",
    "        #print(filename)\n",
    "        flipped_filenames.append('f'+filename)\n",
    "        plt.savefig('data/flips/'+'f'+filename)\n",
    "        if i%1000 == 0:\n",
    "            print(\"1000 processed\")\n",
    "    return flipped_filenames\n",
    "        \n",
    "flipped_filenames = flip_images(X_train)\n",
    "flipped_measurements = -y_train\n",
    "#X_train_flipped = np.fliplr(X_train)\n",
    "#y_train_flipped = -y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.extend(flipped_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6027\n"
     ]
    }
   ],
   "source": [
    "#current_path = 'data/IMG/' + 'f'+X_train[1]\n",
    "#image = mpimg.imread(current_path)\n",
    "#plt.imshow(image)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X_data, y_data, batch_size):\n",
    "    \n",
    "    num_samples = len(X_data)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            X_data_range, y_data_range = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "            if len(X_data_range) < batch_size:\n",
    "                break\n",
    "            for i in range(0, batch_size):\n",
    "                filename = X_data_range[i]\n",
    "                current_path = 'data/IMG/' + filename\n",
    "                batch_x_one = cv2.imread(current_path)\n",
    "                batch_x_one = cv2.cvtColor(batch_x_one, cv2.COLOR_BGR2GRAY)\n",
    "                batch_x_one = np.expand_dims(batch_x_one[:, :], 2)\n",
    "                batch_x.append(batch_x_one)\n",
    "                batch_y.append(y_data_range[i])\n",
    "        #batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "            batch_x = np.asarray(batch_x)\n",
    "            #batch_x = batch_x.reshape(-1, 160, 320, 3)\n",
    "            batch_y = np.asarray(batch_y)\n",
    "            batch_x, batch_y = shuffle(batch_x, batch_y)\n",
    "            yield batch_x, batch_y\n",
    "    \n",
    "batch_x, batch_y = next(generator(X_train, y_train, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(X_train, y_train, batch_size)\n",
    "valid_generator = generator(X_valid, y_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "160\n",
      "(160, 320, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160, 320, 1, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(batch_x[31], cmap='gray')\n",
    "print(len(batch_x))\n",
    "print(len(batch_x[0]))\n",
    "print(batch_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6027"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hon89\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=24, kernel_size=(5, 5), padding=\"same\", strides=(2, 2))`\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BatchNormalization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4796fde9992a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# convolution layer 1, with input: x1 output: x24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# maxpooling layer 1, with input: x24 output: x24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BatchNormalization' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# crop the some of the top and bottom to make image more relevant\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,1)))\n",
    "# doing the normalizaton\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(110,300,1)))\n",
    "# convolution layer 1, with input: x1 output: x24\n",
    "model.add(Conv2D(filters=24, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# maxpooling layer 1, with input: x24 output: x24\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# convolution layer 2, with input: x24, output: x36\n",
    "model.add(Conv2D(filters=36, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# maxpooling layer 2, with input: x36 output: x36\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# convolution layer 3, with input: x36, output: x48\n",
    "model.add(Conv2D(filters=48, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# maxpooling layer 3, with input: x48, output: x48\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# flatten the inputs, prepared for the fully connected layer\n",
    "model.add(Flatten())\n",
    "# fully connected layer 1, with input x48, output: 1024\n",
    "model.add(Dense(1024))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# apply regularization, with a dropout probability of 50%\n",
    "model.add(Dropout(0.5))\n",
    "# fully connected layer 2, with input 1024, output: 256\n",
    "model.add(Dense(256))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Activation('relu'))\n",
    "# output layer, with input: 256, output 1\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hon89\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\hon89\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=6027, validation_data=<generator..., validation_steps=62.78125, verbose=2, shuffle=True, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(X_train), \n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(X_valid)/batch_size,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    nb_epoch=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
