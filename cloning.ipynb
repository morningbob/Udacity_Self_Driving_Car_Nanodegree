{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge tensorflow-gpu --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge keras --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import cv2\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#from keras import backend as K\n",
    "#K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Activation, MaxPooling2D, Lambda, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Conv2D, Cropping2D \n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# generator\n",
    "\n",
    "# read the csv file\n",
    "driving_df_1 = pd.read_csv('driving_log_1.csv')\n",
    "driving_df_2A = pd.read_csv('driving_log_2A.csv')\n",
    "\n",
    "def get_images_filenames_measurements(dataframe):\n",
    "\n",
    "    filenames = []\n",
    "    measurements = []\n",
    "    \n",
    "    correction = 0.15\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        center_text = row[0]\n",
    "        center_i = center_text.find('center')\n",
    "        center_filename = center_text[center_i:]\n",
    "        #center_filenames.append(center_filename)\n",
    "        center_measure = float(row[3])\n",
    "        filenames.append(center_filename)\n",
    "        measurements.append(center_measure)\n",
    "        left_text = row[1]\n",
    "        left_i = left_text.find('left')\n",
    "        left_filename = left_text[left_i:]\n",
    "        #left_filenames.append(left_filename)\n",
    "        left_measure = center_measure + correction\n",
    "        #left_measures.append(left_measure)\n",
    "        filenames.append(left_filename)\n",
    "        measurements.append(left_measure)\n",
    "        right_text = row[2]\n",
    "        right_i = right_text.find('right')\n",
    "        right_filename = right_text[right_i:]\n",
    "        #right_filenames.append(right_filename)\n",
    "        right_measure = center_measure - correction\n",
    "        filenames.append(right_filename)\n",
    "        measurements.append(right_measure)\n",
    "        #right_measures.append(right_measure)\n",
    "    \n",
    "        \n",
    "    return filenames, measurements\n",
    "\n",
    "filenames_1, measurements_1 = get_images_filenames_measurements(driving_df_1)\n",
    "filenames_2, measurements_2 = get_images_filenames_measurements(driving_df_2A)\n",
    "\n",
    "filenames = np.append(np.asarray(filenames_1), np.asarray(filenames_2))\n",
    "measurements = np.append(np.asarray(measurements_1), np.asarray(measurements_2))\n",
    "\n",
    "flips_filenames = []\n",
    "\n",
    "for each in filenames:\n",
    "    flips_filenames.append('f'+each)\n",
    "    \n",
    "flips_measurements = - np.asarray(measurements)\n",
    "\n",
    "total_filenames = np.append(np.asarray(filenames), np.asarray(flips_filenames))\n",
    "total_measurements = np.append(np.asarray(measurements), np.asarray(flips_measurements))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(total_filenames, total_measurements, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X_data, y_data, batch_size):\n",
    "    \n",
    "    num_samples = len(X_data)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            X_data_range, y_data_range = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "            if len(X_data_range) < batch_size:\n",
    "                break\n",
    "            for i in range(0, batch_size):\n",
    "                filename = X_data_range[i]\n",
    "                current_path = 'IMG6/' + filename\n",
    "                #print(current_path)\n",
    "                #batch_x_one = cv2.imread(current_path)\n",
    "                batch_x_one = mpimg.imread(current_path)\n",
    "                #print(batch_x_one.shape)\n",
    "                #if batch_x_one is None:\n",
    "                #    print(\"null\")\n",
    "                #plt.imshow(batch_x_one)\n",
    "                #batch_x_one = cv2.cvtColor(batch_x_one, cv2.COLOR_BGR2GRAY)\n",
    "                #batch_x_one = np.expand_dims(batch_x_one[:, :], 2)\n",
    "                batch_x.append(batch_x_one)\n",
    "                batch_y.append(y_data_range[i])\n",
    "        #batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "            batch_x = np.asarray(batch_x)\n",
    "            #batch_x = batch_x.reshape(-1, 160, 320, 3)\n",
    "            batch_y = np.asarray(batch_y)\n",
    "            batch_x, batch_y = shuffle(batch_x, batch_y)\n",
    "            yield batch_x, batch_y\n",
    "    \n",
    "batch_x, batch_y = next(generator(X_train, y_train, 32))\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "train_generator = generator(X_train, y_train, batch_size)\n",
    "valid_generator = generator(X_valid, y_valid, batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00003, beta_1=0.9, beta_2=0.999, decay=0.000003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_2 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 45, 160, 15)       1140      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 45, 160, 15)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 44, 159, 15)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 22, 80, 64)        24064     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 22, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 21, 79, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 106176)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               53088500  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                25050     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 53,138,805\n",
      "Trainable params: 53,138,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=15, kernel_size=(5, 5), padding=\"same\", strides=(2, 2))`\n",
      "  app.launch_new_instance()\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", strides=(2, 2))`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# crop the some of the top and bottom to make image more relevant\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "# doing the normalizaton\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(90,320,3)))\n",
    "#model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "# convolution layer 1, with input: x1 output: x24\n",
    "#model.add(Conv2D(filters=8, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "# maxpooling layer 1, with input: x24 output: x24\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# convolution layer 2, with input: x24, output: x36\n",
    "model.add(Conv2D(filters=15, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# maxpooling layer 2, with input: x36 output: x36\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# convolution layer 3, with input: x36, output: x48\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='same', subsample=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# maxpooling layer 3, with input: x48, output: x48\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# flatten the inputs, prepared for the fully connected layer\n",
    "model.add(Flatten())\n",
    "# fully connected layer 1, with input x48, output: 1024\n",
    "model.add(Dense(500))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# apply regularization, with a dropout probability of 50%\n",
    "model.add(Dropout(0.5))\n",
    "# fully connected layer 2, with input 1024, output: 256\n",
    "model.add(Dense(50))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Activation('relu'))\n",
    "# output layer, with input: 256, output 1\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"model91.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=54427, validation_data=<generator..., validation_steps=283.484375, verbose=1, shuffle=True, epochs=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "54427/54427 [==============================] - 7656s 141ms/step - loss: 0.0100 - acc: 0.2027 - val_loss: 0.0248 - val_acc: 0.2008\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(X_train), \n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(X_valid)/batch_size,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    nb_epoch=epochs)\n",
    "\n",
    "model.save('model911.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=54427, validation_data=<generator..., validation_steps=283.484375, verbose=1, shuffle=True, callbacks=[<keras.ca..., epochs=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "54427/54427 [==============================] - 7639s 140ms/step - loss: 0.0017 - acc: 0.2041 - val_loss: 0.0247 - val_acc: 0.2009\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.00172, saving model to model91.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91d0f843c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first saved model is model8.h5\n",
    "\n",
    "# fit the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "#new_model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)\n",
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(X_train), \n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(X_valid)/batch_size,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    nb_epoch=epochs,\n",
    "                    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
